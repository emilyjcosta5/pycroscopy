{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesian_inference import AdaptiveBayesianInference\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pyUSID as usid\n",
    "from pyUSID.io.hdf_utils import create_results_group, write_main_dataset, write_simple_attrs, create_empty_dataset, write_ind_val_dsets\n",
    "from pyUSID.io.write_utils import Dimension\n",
    "from bayesian_utils import get_M_dx_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find main dataset and make a temporary copy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_path = 'pzt_nanocap_6_split_bayesian_compensation_R_correction.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the temporary file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-119-38478d0926e7>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-119-38478d0926e7>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    myDict['X'] = [:50]\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(h5_path, mode='r+') as f:\n",
    "    h5_grp = f['Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000']\n",
    "    h5_resh = f['Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data']\n",
    "    subset_grp = h5_grp['Reshaped-Subset_500']\n",
    "    myDict = {} \n",
    "    myDict['X'] = [:50]\n",
    "    myDict['Y'] = [:10]\n",
    "    abi = AdaptiveBayesianInference(h5_resh, Ns=int(1e7))\n",
    "    print(abi.h5_main.n_dim_labels)\n",
    "    #h5_resh_new = abi.slice(slice_dict=myDict, ndim_form=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consider calling test() to check results before calling compute() which computes on the entire dataset and writes back to the HDF5 file\n",
      "Group: <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_000\" (0 members)> had neither the status HDF5 dataset or the legacy attribute: \"last_pixel\".\n",
      "Note: Adaptive_Bayesian has already been performed with the same parameters before. These results will be returned by compute() by default. Set override to True to force fresh computation\n",
      "[<HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_001\" (0 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_003\" (2 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_005\" (4 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_007\" (5 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_009\" (11 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_011\" (11 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_013\" (11 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_015\" (11 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_017\" (11 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_019\" (11 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_021\" (11 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_023\" (11 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_025\" (11 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_027\" (11 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_029\" (11 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_031\" (11 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_033\" (11 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_035\" (9 members)>]\n",
      "Note: Adaptive_Bayesian has already been performed PARTIALLY with the same parameters. compute() will resuming computation in the last group below. To choose a different group call use_patial_computation()Set override to True to force fresh computation or resume from a data group besides the last in the list.\n",
      "[<HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_002\" (0 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_004\" (4 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_006\" (4 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_008\" (11 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_010\" (11 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_012\" (11 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_014\" (11 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_016\" (11 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_018\" (11 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_020\" (11 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_022\" (11 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_024\" (11 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_026\" (11 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_028\" (11 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_030\" (11 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_032\" (11 members)>, <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data-Adaptive_Bayesian_034\" (9 members)>]\n",
      "(500, 500)\n",
      "250000\n",
      "/Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped-Subset_500\n",
      "├ Position_Indices\n",
      "├ Position_Values\n",
      "├ Spectroscopic_Indices\n",
      "├ Spectroscopic_R_Indices\n",
      "├ Spectroscopic_R_Values\n",
      "├ Spectroscopic_Values\n",
      "h5 group and file OK\n",
      "quantity, units, main_data_name all OK\n",
      "Provided numpy or Dask array for main_data OK so far\n",
      "Provided h5 position indices and values OK\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "index 1 in shape of h5_inds: (1, 250) and main_data: (500, 500) should be equal.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-884128138b4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mh5_pos_inds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh5_pos_inds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh5_pos_vals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh5_pos_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mh5_spec_inds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh5_spec_inds_R\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     h5_spec_vals=h5_spec_vals_R, verbose=True) #this one\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0musid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhdf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset_grp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Done: h5_spec_inds_R, h5_spec_vals_R = write_ind_val_dsets(subset_grp, Dimension(\"Bias\", \"V\", 2*M), is_spectral=True, base_name=\"Spectroscopic_R\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pyUSID/io/hdf_utils/model.py\u001b[0m in \u001b[0;36mwrite_main_dataset\u001b[0;34m(h5_parent_group, main_data, main_data_name, quantity, units, pos_dims, spec_dims, main_dset_attrs, h5_pos_inds, h5_pos_vals, h5_spec_inds, h5_spec_vals, aux_spec_prefix, aux_pos_prefix, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mh5_spec_inds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mh5_spec_vals\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0;31m# The provided datasets override fresh building instructions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m         \u001b[0mvalidate_anc_h5_dsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5_spec_inds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5_spec_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_spectroscopic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Provided h5 spectroscopic datasets were OK'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pyUSID/io/hdf_utils/simple.py\u001b[0m in \u001b[0;36mvalidate_anc_h5_dsets\u001b[0;34m(h5_inds, h5_vals, main_shape, is_spectroscopic)\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mh5_inds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mis_spectroscopic\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmain_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mis_spectroscopic\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         raise ValueError('index {} in shape of h5_inds: {} and main_data: {} should be equal'\n\u001b[0;32m--> 348\u001b[0;31m                          '.'.format(int(is_spectroscopic), h5_inds.shape, main_shape))\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: index 1 in shape of h5_inds: (1, 250) and main_data: (500, 500) should be equal."
     ]
    }
   ],
   "source": [
    "with h5py.File(h5_path, mode='r+') as f:\n",
    "    h5_grp = f['Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000']\n",
    "    h5_resh = f['Measurement_000/Channel_000/Raw_Data-FFT_Filtering_000/Filtered_Data-Reshape_000/Reshaped_Data']\n",
    "    subset_grp = h5_grp['Reshaped-Subset_500']\n",
    "    abi = AdaptiveBayesianInference(h5_resh, Ns=int(1e7))\n",
    "    h5_resh_new = abi.slice(slice_dict=None, ndim_form=False, verbose=True)\n",
    "    #np.asarray(h5_resh[0:500])\n",
    "    print(h5_resh_new.shape)\n",
    "    print(h5_resh_new.size)\n",
    "    h5_pos_vals = subset_grp['Position_Values']\n",
    "    usid.hdf_utils.print_tree(subset_grp)\n",
    "    h5_pos_inds = subset_grp['Position_Indices']\n",
    "    h5_spec_inds_R = subset_grp['Spectroscopic_R_Indices']\n",
    "    h5_spec_vals_R = subset_grp['Spectroscopic_R_Values']\n",
    "    #print(abi.h5_main.h5_spec_vals[()][:500])\n",
    "    #print(h5_spec_vals_R.shape)\n",
    "    #ex_wave = h5_pos_vals[()]\n",
    "    #full_V = ex_wave[0][::1]    \n",
    "    #M, dx, x = get_M_dx_x(V0=max(full_V), M=125)\n",
    "    #h5_spec_vals_R[()] = abi.h5_main.h5_spec_vals[()]\n",
    "    #print(h5_spec_vals_R.shape)\n",
    "    quantity = main_data_name = \"Resistance\"\n",
    "    units = \"GOhmns\"\n",
    "    pos_dims = spec_dims = None\n",
    "    \n",
    "    #del h5_pos_vals\n",
    "    #h5_pos_inds, h5_pos_vals = usid.hdf_utils.write_ind_val_dsets(subset_grp, Dimension(\"Bias\", \"V\", 500), is_spectral=False)\n",
    "    # Maybe not: h5_pos_inds, h5_pos_vals = usid.hdf_utils.write_ind_val_dsets(subset_grp, Dimension(\"Bias\", \"V\", 500), is_spectral=True)\n",
    "    \n",
    "    new_h5_resh = write_main_dataset(subset_grp, h5_resh_new, main_data_name, quantity, units, pos_dims, spec_dims, \n",
    "    h5_pos_inds=h5_pos_inds,h5_pos_vals=h5_pos_vals,\n",
    "    h5_spec_inds=h5_spec_inds_R,\n",
    "    h5_spec_vals=h5_spec_vals_R, verbose=True) #this one\n",
    "    usid.hdf_utils.print_tree(subset_grp)\n",
    "    # Done: h5_spec_inds_R, h5_spec_vals_R = write_ind_val_dsets(subset_grp, Dimension(\"Bias\", \"V\", 2*M), is_spectral=True, base_name=\"Spectroscopic_R\")\n",
    "    \n",
    "#h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run and visualize test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = abi.test()\n",
    "test_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the compute function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = abi.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare to visualize process data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not sure if you need these here or not\n",
    "h5_filt_grp = usid.hdf_utils.find_results_groups(h5Main, \"FFT_Filtering\")[-1]\n",
    "h5_filt = h5_filt_grp[\"Filtered_Data\"]\n",
    "h5_resh_grp = usid.hdf_utils.find_results_groups(h5_filt, \"Reshape\")[-1]\n",
    "h5_resh = usid.USIDataset(h5_resh_grp[\"Reshaped_Data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the processed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_utils.simple_graphs(verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
